---
title: "p8105_hw5_yz4720"
author: "Jasmine Zhang"
date: "2023-11-15"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(viridis)
set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Problem 1
### Homicide dataset
```{r}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown"))|> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolution = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"))|>  
  filter(city_state != "Tulsa, AL") 
```

The tidy dataset has `r nrow(homicide_df)` observations. Variables include the victim name, race, age, and sex; the date the homicide was reported; and the location of the homicide. `city_state` variable is created that includes both city and state, and a `resolution` variable is created to indicate whether the case was closed by arrest. The one entry in Tulsa, AL is excluded because it is not a major US city and is most likely a data entry error. 

### Homicide status by city
```{r}
city_homicide_df = 
  homicide_df %>% 
  select(city_state, disposition, resolution) %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolution == "unsolved"))
```

### Baltimore: unsolved homicide estimation

```{r}
bmore_test = 
  prop.test(
    x = filter(city_homicide_df, city_state == "Baltimore, MD") %>% pull(hom_unsolved),
    n = filter(city_homicide_df, city_state == "Baltimore, MD") %>% pull(hom_total)) 

broom::tidy(bmore_test) 
```

### All cities: unsolved homicide estimation

```{r}
test_results = 
  city_homicide_df %>% 
  mutate(
    prop_tests = map2(hom_unsolved, hom_total, \(x, y) prop.test(x = x, n = y)),
    tidy_tests = map(prop_tests, broom::tidy)) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high) %>% 
  mutate(city_state = fct_reorder(city_state, estimate))
```

```{r}
test_results %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Chicago has the highest proportion of unsolved homicides among all the cities. 


# Problem 2
### Import study data 

```{r message=FALSE, warning=FALSE}
files_df = tibble(
    filename = list.files("./data/problem2/"),
    path = str_c("./data/problem2/", filename)) |>
  mutate(data = map(path, read_csv)) |>
  unnest()
files_df
```

### Tidy study data 

```{r}
files_tidy_df = files_df|>
  janitor::clean_names() |>
  separate(filename, into = c("group", "subject_id"), sep = "_") |>
  mutate(
    group = case_match(group, 
                     "con" ~ "control", 
                     "exp" ~ "experiment"),
    subject_id = str_replace(subject_id, ".csv", ""))|>
  pivot_longer(week_1:week_8, 
               names_to = "week",
               names_prefix = "week_",
               values_to = "observation") |>
  select(group, subject_id, week, observation)
files_tidy_df
```

### Plot: observation over time 

```{r}
files_tidy_df|>
  ggplot(aes(x = week, y = observation, group = subject_id, color = subject_id)) +
  geom_point()+
  geom_line() +
  facet_grid(.~group) +
  labs(title = "Observations on each subject over time", 
       x = "weeks", y = "observations") 
```

In the control group, observations remain relatively stable over the 8-week time period. In the experiment group, observations increase over time for all 10 subjects over the 8-week time period. The value of observation is higher at 8-week for experiment group compared to control group. 

# Problem 3
### Dataset: X ~ N(0, 5)

```{r}
simulation = function(n=30, mu, sd=5){
  x = rnorm(n, mean=mu, sd)
  test_result = t.test(x)|>
  broom::tidy() |>
  select(estimate, p.value)
}

sim_mu0 = rerun(5000, simulation(mu = 0)) |> 
  bind_rows() |> 
  select(estimate, p.value)
```

### Dataset: X ~ N(mu, 5), mu = {1, 2, 3, 4, 5 ,6}

```{r}
sim_mu = tibble(mu = c(0, 1, 2, 3, 4, 5, 6)) |> 
  mutate(
    output_list = map(.x = mu, ~ rerun(5000, simulation(mu = .x, sd=5))),
    estimate_df = map(output_list, bind_rows))|>  
  unnest(estimate_df) |> 
  select(-output_list)
```

### Plot: True value vs. power of the test

```{r}
value_power = sim_mu |>
  group_by(mu) |>
  summarize(reject = sum(p.value < 0.05)/5000) |>
  ggplot(aes(x = mu, y = reject)) +
  geom_point() +
  geom_line() +
  labs(title = "Effect size and power", x = "True value of mean", y = "Power of the test") 
value_power
```

As the true value of mu increases, the proportion of times the null was rejected also increases. Thus, there is a positive relationship between effect size and power. 

### Plot: Estimate vs. True Value

```{r}
estimate_mean= sim_mu |> 
  group_by(mu) |> 
  mutate(avg_mean = mean(estimate)) |> 
  ggplot(aes(x = mu, y = avg_mean ))+
  geom_point() +
  geom_line() +
  labs(title = "Average Estimate vs. True Value of Mean", x = "True value of mean", y = "Average estimate of mean") 
estimate_mean
```

The plot shows that average estimate of the mean roughly equals to the true value of mean.

### Plot: Estimate (null rejected) vs. True Value

```{r}
null_reject =  sim_mu |> 
  filter(p.value < 0.05) |> 
  group_by(mu) |> 
  mutate(avg_mean = mean(estimate)) |> 
  ggplot(aes(x = mu, y = avg_mean ))+
  geom_point()+
  geom_line() +
  labs(title = "Average Estimate vs. True Value of Mean among Null Rejected Samples",
    x = "True value of mean", y = "Average estimate of mean") 
null_reject
```

The sample average of estimate of mean across tests for which the null is rejected approximately equal to the true value of mean when the true value of mean is greater or equal to 4. This corresponds to the relationship found between effect size and power of the test. As the effect size increases, any statistically significant difference can be easier to be found, hence increasing the power of the test.
